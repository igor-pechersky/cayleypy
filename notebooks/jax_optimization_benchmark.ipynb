{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX/TPU Optimization Benchmarks\n",
    "\n",
    "This notebook demonstrates the performance improvements from the JAX/TPU optimizations applied to CayleyPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Callable\n",
    "\n",
    "try:\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    JAX_AVAILABLE = True\n",
    "except ImportError:\n",
    "    JAX_AVAILABLE = False\n",
    "    jax = None\n",
    "    jnp = None\n",
    "    print(\"JAX not available - using numpy for tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CayleyPy components\n",
    "if JAX_AVAILABLE:\n",
    "    from cayleypy.jax_tensor_ops import (\n",
    "        unique_with_indices, isin_via_searchsorted, sort_with_indices,\n",
    "        batch_matmul, vectorized_element_wise_equal, batch_isin_via_searchsorted,\n",
    "        distributed_batch_matmul, memory_efficient_unique, optimized_chunked_operation\n",
    "    )\n",
    "    \n",
    "    from cayleypy.jax_hasher import (\n",
    "        JAXStateHasher, OptimizedJAXStateHasher, vectorized_hash_states,\n",
    "        distributed_hash_states, memory_efficient_hash_large_batch\n",
    "    )\n",
    "    \n",
    "    print(f\"JAX version: {jax.__version__}\")\n",
    "    print(f\"Available devices: {jax.devices()}\")\n",
    "    print(f\"Default backend: {jax.default_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_function(func, *args, **kwargs):\n",
    "    \"\"\"Time a function execution.\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time, result\n",
    "\n",
    "\n",
    "def run_comparison(name, funcs, *args, **kwargs):\n",
    "    \"\"\"Run and compare multiple implementations of the same function.\"\"\"\n",
    "    print(f\"\\n=== Testing {name} ===\")\n",
    "    results = {}\n",
    "    times = {}\n",
    "    \n",
    "    baseline_impl = next(iter(funcs.keys()))\n",
    "    \n",
    "    for impl_name, func in funcs.items():\n",
    "        time_taken, result = time_function(func, *args, **kwargs)\n",
    "        results[impl_name] = result\n",
    "        times[impl_name] = time_taken\n",
    "        print(f\"{impl_name}: {time_taken:.6f} seconds\")\n",
    "    \n",
    "    # Calculate speedups\n",
    "    baseline_time = times[baseline_impl]\n",
    "    speedups = {}\n",
    "    for impl_name, time_taken in times.items():\n",
    "        if impl_name != baseline_impl:\n",
    "            speedup = baseline_time / time_taken\n",
    "            speedups[impl_name] = speedup\n",
    "            print(f\"{impl_name} speedup: {speedup:.2f}x\")\n",
    "    \n",
    "    # Verify results match\n",
    "    baseline_result = results[baseline_impl]\n",
    "    for impl_name, result in results.items():\n",
    "        if impl_name != baseline_impl:\n",
    "            if JAX_AVAILABLE:\n",
    "                try:\n",
    "                    match = jnp.array_equal(result, baseline_result)\n",
    "                    print(f\"{impl_name} results match baseline: {match}\")\n",
    "                except:\n",
    "                    print(f\"{impl_name} results could not be compared\")\n",
    "            else:\n",
    "                try:\n",
    "                    match = np.array_equal(result, baseline_result)\n",
    "                    print(f\"{impl_name} results match baseline: {match}\")\n",
    "                except:\n",
    "                    print(f\"{impl_name} results could not be compared\")\n",
    "    \n",
    "    return times, speedups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Test unique_with_indices\n",
    "    array = jnp.array([3, 1, 2, 1, 3, 2, 4, 5, 6, 7, 8, 9, 10] * 100)  # Make it larger\n",
    "    unique_times, unique_speedups = run_comparison(\"unique_with_indices\", {\n",
    "        \"jnp.unique\": lambda x: jnp.unique(x, return_inverse=True, return_counts=True),\n",
    "        \"optimized\": lambda x: unique_with_indices(x, True, True)\n",
    "    }, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Test isin with different sizes\n",
    "    sizes = [100, 1000, 10000]\n",
    "    isin_times = {\"standard\": {}, \"optimized\": {}}\n",
    "    \n",
    "    for size in sizes:\n",
    "        elements = jnp.arange(size)\n",
    "        test_elements = jnp.arange(0, size, 10)  # Every 10th element\n",
    "        \n",
    "        print(f\"\\n=== Testing isin with size {size} ===\")\n",
    "        \n",
    "        # Standard implementation (only for small sizes)\n",
    "        if size <= 1000:\n",
    "            start_time = time.time()\n",
    "            _ = jnp.array([e in test_elements for e in elements])\n",
    "            end_time = time.time()\n",
    "            isin_times[\"standard\"][size] = end_time - start_time\n",
    "            print(f\"standard: {isin_times['standard'][size]:.6f} seconds\")\n",
    "        \n",
    "        # Optimized implementation\n",
    "        start_time = time.time()\n",
    "        _ = isin_via_searchsorted(elements, test_elements)\n",
    "        end_time = time.time()\n",
    "        isin_times[\"optimized\"][size] = end_time - start_time\n",
    "        print(f\"optimized: {isin_times['optimized'][size]:.6f} seconds\")\n",
    "        \n",
    "        # Calculate speedup if standard is available\n",
    "        if size in isin_times[\"standard\"]:\n",
    "            speedup = isin_times[\"standard\"][size] / isin_times[\"optimized\"][size]\n",
    "            print(f\"Speedup: {speedup:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Plot isin results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    standard_sizes = sorted(isin_times[\"standard\"].keys())\n",
    "    standard_times = [isin_times[\"standard\"][size] for size in standard_sizes]\n",
    "    plt.plot(standard_sizes, standard_times, marker='o', label=\"standard\")\n",
    "    \n",
    "    optimized_sizes = sorted(isin_times[\"optimized\"].keys())\n",
    "    optimized_times = [isin_times[\"optimized\"][size] for size in optimized_sizes]\n",
    "    plt.plot(optimized_sizes, optimized_times, marker='o', label=\"optimized\")\n",
    "    \n",
    "    plt.title(\"isin Performance Comparison\")\n",
    "    plt.xlabel(\"Array Size\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Test batch operations\n",
    "    elements_batch = jnp.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "    test_elements = jnp.array([2, 5, 8, 11])\n",
    "    batch_times, batch_speedups = run_comparison(\"batch_isin\", {\n",
    "        \"loop\": lambda x, y: jnp.stack([isin_via_searchsorted(row, y) for row in x]),\n",
    "        \"vectorized\": lambda x, y: batch_isin_via_searchsorted(x, y)\n",
    "    }, elements_batch, test_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Test matrix multiplication with different sizes\n",
    "    sizes = [10, 100, 500, 1000]\n",
    "    matmul_times = {\"standard\": {}, \"optimized\": {}}\n",
    "    \n",
    "    for size in sizes:\n",
    "        a = jnp.ones((size, size))\n",
    "        b = jnp.ones((size, size))\n",
    "        \n",
    "        print(f\"\\n=== Testing matmul with size {size}x{size} ===\")\n",
    "        \n",
    "        # Standard implementation\n",
    "        start_time = time.time()\n",
    "        _ = jnp.matmul(a, b)\n",
    "        end_time = time.time()\n",
    "        matmul_times[\"standard\"][size] = end_time - start_time\n",
    "        print(f\"standard: {matmul_times['standard'][size]:.6f} seconds\")\n",
    "        \n",
    "        # Optimized implementation\n",
    "        start_time = time.time()\n",
    "        _ = batch_matmul(a, b)\n",
    "        end_time = time.time()\n",
    "        matmul_times[\"optimized\"][size] = end_time - start_time\n",
    "        print(f\"optimized: {matmul_times['optimized'][size]:.6f} seconds\")\n",
    "        \n",
    "        # Calculate speedup\n",
    "        speedup = matmul_times[\"standard\"][size] / matmul_times[\"optimized\"][size]\n",
    "        print(f\"Speedup: {speedup:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Plot matmul results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    standard_sizes = sorted(matmul_times[\"standard\"].keys())\n",
    "    standard_times = [matmul_times[\"standard\"][size] for size in standard_sizes]\n",
    "    plt.plot(standard_sizes, standard_times, marker='o', label=\"standard\")\n",
    "    \n",
    "    optimized_sizes = sorted(matmul_times[\"optimized\"].keys())\n",
    "    optimized_times = [matmul_times[\"optimized\"][size] for size in optimized_sizes]\n",
    "    plt.plot(optimized_sizes, optimized_times, marker='o', label=\"optimized\")\n",
    "    \n",
    "    plt.title(\"Matrix Multiplication Performance Comparison\")\n",
    "    plt.xlabel(\"Matrix Size\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Function Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Test hash functions with different batch sizes\n",
    "    sizes = [100, 1000, 10000, 100000]\n",
    "    state_size = 10\n",
    "    hash_times = {\"standard\": {}, \"vectorized\": {}, \"optimized\": {}}\n",
    "    \n",
    "    # Create hashers\n",
    "    standard_hasher = JAXStateHasher(state_size=state_size, random_seed=42)\n",
    "    optimized_hasher = OptimizedJAXStateHasher(state_size=state_size, random_seed=42)\n",
    "    \n",
    "    for size in sizes:\n",
    "        states = jnp.ones((size, state_size), dtype=jnp.int32)\n",
    "        states = states.at[:, 0].set(jnp.arange(size))  # Make states unique\n",
    "        \n",
    "        print(f\"\\n=== Testing hash_states with batch size {size} ===\")\n",
    "        \n",
    "        # Standard implementation\n",
    "        start_time = time.time()\n",
    "        standard_result = standard_hasher.hash_states(states)\n",
    "        end_time = time.time()\n",
    "        hash_times[\"standard\"][size] = end_time - start_time\n",
    "        print(f\"standard: {hash_times['standard'][size]:.6f} seconds\")\n",
    "        \n",
    "        # Vectorized implementation\n",
    "        start_time = time.time()\n",
    "        vectorized_result = vectorized_hash_states(states, standard_hasher)\n",
    "        end_time = time.time()\n",
    "        hash_times[\"vectorized\"][size] = end_time - start_time\n",
    "        print(f\"vectorized: {hash_times['vectorized'][size]:.6f} seconds\")\n",
    "        \n",
    "        # Optimized implementation\n",
    "        start_time = time.time()\n",
    "        optimized_result = optimized_hasher.hash_states_optimized(states)\n",
    "        end_time = time.time()\n",
    "        hash_times[\"optimized\"][size] = end_time - start_time\n",
    "        print(f\"optimized: {hash_times['optimized'][size]:.6f} seconds\")\n",
    "        \n",
    "        # Calculate speedups\n",
    "        vectorized_speedup = hash_times[\"standard\"][size] / hash_times[\"vectorized\"][size]\n",
    "        optimized_speedup = hash_times[\"standard\"][size] / hash_times[\"optimized\"][size]\n",
    "        print(f\"Vectorized speedup: {vectorized_speedup:.2f}x\")\n",
    "        print(f\"Optimized speedup: {optimized_speedup:.2f}x\")\n",
    "        \n",
    "        # Verify results match\n",
    "        vectorized_match = jnp.array_equal(standard_result, vectorized_result)\n",
    "        optimized_match = jnp.array_equal(standard_result, optimized_result)\n",
    "        print(f\"Vectorized results match: {vectorized_match}\")\n",
    "        print(f\"Optimized results match: {optimized_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Plot hash function results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for method, times in hash_times.items():\n",
    "        sizes = sorted(times.keys())\n",
    "        time_values = [times[size] for size in sizes]\n",
    "        plt.plot(sizes, time_values, marker='o', label=method)\n",
    "    \n",
    "    plt.title(\"Hash Function Performance Comparison\")\n",
    "    plt.xlabel(\"Batch Size\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Plot speedups\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    sizes = sorted(hash_times[\"standard\"].keys())\n",
    "    vectorized_speedups = [hash_times[\"standard\"][size] / hash_times[\"vectorized\"][size] for size in sizes]\n",
    "    optimized_speedups = [hash_times[\"standard\"][size] / hash_times[\"optimized\"][size] for size in sizes]\n",
    "    \n",
    "    plt.plot(sizes, vectorized_speedups, marker='o', label=\"vectorized\")\n",
    "    plt.plot(sizes, optimized_speedups, marker='o', label=\"optimized\")\n",
    "    \n",
    "    plt.title(\"Hash Function Speedup Comparison\")\n",
    "    plt.xlabel(\"Batch Size\")\n",
    "    plt.ylabel(\"Speedup (x)\")\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Efficiency Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Test memory-efficient operations\n",
    "    array_size = 10000\n",
    "    chunk_size = 1000\n",
    "    array = jnp.arange(array_size)\n",
    "    \n",
    "    def sum_operation(chunk):\n",
    "        return jnp.sum(chunk, axis=0)\n",
    "    \n",
    "    chunked_times, chunked_speedups = run_comparison(\"chunked_operation\", {\n",
    "        \"standard\": lambda x: chunked_operation(x, sum_operation, chunk_size),\n",
    "        \"optimized\": lambda x: optimized_chunked_operation(x, sum_operation, chunk_size, True)\n",
    "    }, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Test memory-efficient unique\n",
    "    array_size = 100000\n",
    "    array = jnp.concatenate([jnp.arange(array_size // 10)] * 10)  # Repeated elements\n",
    "    \n",
    "    unique_times, unique_speedups = run_comparison(\"memory_efficient_unique\", {\n",
    "        \"standard\": jnp.unique,\n",
    "        \"memory_efficient\": lambda x: memory_efficient_unique(x, 0.1)  # Small memory limit to force chunking\n",
    "    }, array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Performance Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Collect all speedups\n",
    "    all_speedups = {\n",
    "        \"isin\": {size: isin_times[\"standard\"][size] / isin_times[\"optimized\"][size] \n",
    "                for size in isin_times[\"standard\"] if size in isin_times[\"optimized\"]},\n",
    "        \"matmul\": {size: matmul_times[\"standard\"][size] / matmul_times[\"optimized\"][size] \n",
    "                  for size in matmul_times[\"standard\"] if size in matmul_times[\"optimized\"]},\n",
    "        \"hash_vectorized\": {size: hash_times[\"standard\"][size] / hash_times[\"vectorized\"][size] \n",
    "                          for size in hash_times[\"standard\"] if size in hash_times[\"vectorized\"]},\n",
    "        \"hash_optimized\": {size: hash_times[\"standard\"][size] / hash_times[\"optimized\"][size] \n",
    "                         for size in hash_times[\"standard\"] if size in hash_times[\"optimized\"]}\n",
    "    }\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\n=== Summary of Performance Improvements ===\")\n",
    "    print(\"Operation | Size | Speedup\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for operation, speedups in all_speedups.items():\n",
    "        for size, speedup in speedups.items():\n",
    "            print(f\"{operation} | {size} | {speedup:.2f}x\")\n",
    "    \n",
    "    # Calculate average speedups\n",
    "    avg_speedups = {}\n",
    "    for operation, speedups in all_speedups.items():\n",
    "        avg_speedups[operation] = sum(speedups.values()) / len(speedups)\n",
    "    \n",
    "    print(\"\\n=== Average Speedups ===\")\n",
    "    for operation, avg_speedup in avg_speedups.items():\n",
    "        print(f\"{operation}: {avg_speedup:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JAX_AVAILABLE:\n",
    "    # Plot average speedups\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    operations = list(avg_speedups.keys())\n",
    "    speedup_values = [avg_speedups[op] for op in operations]\n",
    "    \n",
    "    plt.bar(operations, speedup_values)\n",
    "    plt.axhline(y=1.0, color='r', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    plt.title(\"Average Speedup by Operation\")\n",
    "    plt.xlabel(\"Operation\")\n",
    "    plt.ylabel(\"Average Speedup (x)\")\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add speedup values on top of bars\n",
    "    for i, v in enumerate(speedup_values):\n",
    "        plt.text(i, v + 0.1, f\"{v:.2f}x\", ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The JAX/TPU optimizations have significantly improved the performance of CayleyPy's tensor operations and hash functions. Key improvements include:\n",
    "\n",
    "1. **Vectorization**: Using `vmap` for batch operations provides substantial speedups\n",
    "2. **JIT Compilation**: Proper use of `@jit` and static shapes improves compilation efficiency\n",
    "3. **Memory Efficiency**: Chunked operations allow processing of larger datasets\n",
    "4. **TPU Optimization**: Specialized implementations for TPU hardware\n",
    "\n",
    "These optimizations make CayleyPy more efficient for large-scale graph processing on TPU hardware."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}