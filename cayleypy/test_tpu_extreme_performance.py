#!/usr/bin/env python3
"""
Extreme TPU Performance Test for Very Large Graphs.

This script tests TPU BFS on the largest feasible graphs to demonstrate
where TPU performance advantages should be most evident.
"""

import time
import logging
import math
from typing import Dict, Any, List, Tuple

try:
    import jax
    import jax.numpy as jnp
    JAX_AVAILABLE = True
except ImportError:
    JAX_AVAILABLE = False
    jax = None  # type: ignore
    jnp = None  # type: ignore

from .tpu_backend import get_tpu_backend
from .tpu_bfs import tpu_bfs, create_tpu_bfs
from .bfs_numpy import bfs_numpy
from .graphs_lib import PermutationGroups
from .cayley_graph import CayleyGraph


def create_high_parallelism_graphs():
    """Create graphs optimized for TPU parallelism."""
    graphs = []
    
    # High-generator graphs for maximum parallelism
    try:
        # S7 with all transpositions (21 generators) - high parallelism
        graphs.append((
            PermutationGroups.all_transpositions(7),
            "S7_AllTranspositions_21gen",
            5,  # Limited diameter to keep it feasible
            "High generator count for maximum TPU parallelism"
        ))
        
        # S8 with all transpositions (28 generators) - very high parallelism
        graphs.append((
            PermutationGroups.all_transpositions(8),
            "S8_AllTranspositions_28gen", 
            4,  # Very limited diameter
            "Maximum generator count for TPU vector operations"
        ))
        
        # Large Coxeter graphs with controlled diameter
        graphs.append((
            PermutationGroups.coxeter(10),
            "S10_Coxeter_10gen",
            8,  # Controlled diameter
            "Large state space with controlled complexity"
        ))
        
        # Pancake graphs with large n
        graphs.append((
            PermutationGroups.pancake(9),
            "Pancake_9_8gen",
            6,  # Limited diameter
            "Large factorial state space"
        ))
        
    except Exception as e:
        print(f"Error creating graphs: {e}")
    
    return graphs


def run_extreme_performance_test():
    """Run extreme performance test on carefully selected large graphs."""
    print("TPU BFS EXTREME PERFORMANCE TEST")
    print("=" * 80)
    print("Testing TPU performance on graphs optimized for parallel processing")
    print("=" * 80)
    
    if not JAX_AVAILABLE:
        print("‚ùå JAX not available")
        return False
    
    try:
        backend = get_tpu_backend()
        if not backend.is_available:
            print("‚ùå TPU not available")
            return False
        
        print(f"‚úÖ TPU Backend Available")
        print(f"   Device count: {backend.get_device_info()['device_count']}")
        print(f"   HBM per chip: {backend.get_device_info()['capabilities']['hbm_per_chip_gb']}GB")
        print(f"   Systolic array: {backend.get_device_info()['capabilities']['systolic_array_size']}")
        
    except Exception as e:
        print(f"‚ùå TPU backend error: {e}")
        return False
    
    # Get optimized test graphs
    test_graphs = create_high_parallelism_graphs()
    
    if not test_graphs:
        print("‚ùå No test graphs available")
        return False
    
    results = []
    performance_successes = 0
    
    for graph_def, name, max_diameter, description in test_graphs:
        print(f"\n{'='*80}")
        print(f"TESTING: {name}")
        print(f"Description: {description}")
        print(f"{'='*80}")
        
        try:
            graph = CayleyGraph(graph_def)
            
            # Estimate complexity
            n = graph.definition.state_size
            generators = len(graph.definition.generators_permutations)
            total_states = math.factorial(n) if graph.definition.is_permutation_group() else n**10
            
            print(f"State size (n): {n}")
            print(f"Generators: {generators}")
            print(f"Max diameter: {max_diameter}")
            print(f"Estimated total states: {total_states:,}")
            
            # Skip if too large
            if total_states > 10**9:  # 1 billion states max
                print(f"‚ö†Ô∏è  Skipping - too large ({total_states:,} states)")
                continue
            
            # CPU Benchmark
            print(f"\nüñ•Ô∏è  Running CPU BFS...")
            cpu_start = time.time()
            cpu_result = bfs_numpy(graph, max_diameter)
            cpu_time = time.time() - cpu_start
            
            total_states_found = sum(cpu_result)
            actual_diameter = len(cpu_result) - 1
            
            print(f"   ‚úÖ CPU completed in {cpu_time:.3f}s")
            print(f"   üìä Actual diameter: {actual_diameter}")
            print(f"   üìä States found: {total_states_found:,}")
            print(f"   üìä CPU throughput: {total_states_found/cpu_time:,.0f} states/sec")
            
            # TPU Benchmark with multiple runs for accuracy
            print(f"\nüöÄ Running TPU BFS...")
            
            # First run (compilation + execution)
            print(f"   üîÑ First run (with compilation)...")
            tpu_start = time.time()
            tpu_result = tpu_bfs(graph, max_diameter)
            first_run_time = time.time() - tpu_start
            
            # Second run (execution only)
            print(f"   üîÑ Second run (execution only)...")
            exec_start = time.time()
            tpu_result_2 = tpu_bfs(graph, max_diameter)
            exec_time = time.time() - exec_start
            
            # Third run for consistency
            print(f"   üîÑ Third run (consistency check)...")
            consistency_start = time.time()
            tpu_result_3 = tpu_bfs(graph, max_diameter)
            consistency_time = time.time() - consistency_start
            
            # Verify all results are identical
            results_consistent = (cpu_result == tpu_result == tpu_result_2 == tpu_result_3)
            
            # Calculate performance metrics
            compilation_time = first_run_time - exec_time
            best_exec_time = min(exec_time, consistency_time)
            speedup = cpu_time / best_exec_time if best_exec_time > 0 else 0
            tpu_throughput = total_states_found / best_exec_time if best_exec_time > 0 else 0
            
            print(f"   ‚úÖ TPU first run: {first_run_time:.3f}s")
            print(f"   üîß Compilation time: {compilation_time:.3f}s")
            print(f"   ‚ö° Best execution time: {best_exec_time:.3f}s")
            print(f"   üìä TPU throughput: {tpu_throughput:,.0f} states/sec")
            print(f"   ‚úÖ Results consistent: {'Yes' if results_consistent else 'No'}")
            
            # Performance analysis
            print(f"\nüìà PERFORMANCE ANALYSIS:")
            print(f"   CPU time: {cpu_time:.3f}s")
            print(f"   TPU execution time: {best_exec_time:.3f}s")
            print(f"   Speedup: {speedup:.2f}x")
            print(f"   Throughput improvement: {tpu_throughput/max(total_states_found/cpu_time, 1):,.2f}x")
            
            # Determine success
            if speedup >= 1.0:
                print(f"   üéâ SUCCESS: TPU is {speedup:.2f}x faster!")
                performance_successes += 1
                status = "SUCCESS"
            elif speedup >= 0.5:
                print(f"   ‚úÖ COMPETITIVE: TPU is {speedup:.2f}x (acceptable)")
                status = "COMPETITIVE"
            else:
                print(f"   ‚ö†Ô∏è  NEEDS OPTIMIZATION: TPU is {speedup:.2f}x")
                status = "NEEDS_OPTIMIZATION"
            
            # Store results
            results.append({
                'name': name,
                'n': n,
                'generators': generators,
                'cpu_time': cpu_time,
                'tpu_time': best_exec_time,
                'speedup': speedup,
                'states_found': total_states_found,
                'consistent': results_consistent,
                'status': status
            })
            
        except Exception as e:
            print(f"   ‚ùå Test failed: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # Final summary
    print(f"\n{'='*80}")
    print("EXTREME PERFORMANCE TEST SUMMARY")
    print(f"{'='*80}")
    
    if results:
        print(f"\nüìä DETAILED RESULTS:")
        print(f"{'Graph':<25} {'n':<3} {'Gen':<4} {'CPU':<8} {'TPU':<8} {'Speedup':<8} {'Status':<12} {'‚úì'}")
        print(f"{'-'*80}")
        
        for r in results:
            name = r['name'][:24]
            n = r['n']
            gen = r['generators']
            cpu = f"{r['cpu_time']:.3f}s"
            tpu = f"{r['tpu_time']:.3f}s"
            speedup = f"{r['speedup']:.2f}x"
            status = r['status'][:11]
            check = "‚úÖ" if r['consistent'] else "‚ùå"
            
            print(f"{name:<25} {n:<3} {gen:<4} {cpu:<8} {tpu:<8} {speedup:<8} {status:<12} {check}")
        
        # Statistics
        total_tests = len(results)
        successful_speedups = sum(1 for r in results if r['speedup'] >= 1.0)
        competitive_results = sum(1 for r in results if r['speedup'] >= 0.5)
        avg_speedup = sum(r['speedup'] for r in results) / len(results)
        max_speedup = max(r['speedup'] for r in results)
        
        print(f"\nüéØ PERFORMANCE STATISTICS:")
        print(f"   Total tests: {total_tests}")
        print(f"   Successful speedups (‚â•1.0x): {successful_speedups}")
        print(f"   Competitive results (‚â•0.5x): {competitive_results}")
        print(f"   Average speedup: {avg_speedup:.2f}x")
        print(f"   Maximum speedup: {max_speedup:.2f}x")
        print(f"   Success rate: {successful_speedups/total_tests:.1%}")
        
        # Final assessment
        if successful_speedups > 0:
            print(f"\nüéâ EXTREME PERFORMANCE TEST: SUCCESS!")
            print(f"   TPU demonstrates performance advantages on {successful_speedups}/{total_tests} large graphs")
            print(f"   Maximum speedup achieved: {max_speedup:.2f}x")
            return True
        elif competitive_results > 0:
            print(f"\n‚úÖ EXTREME PERFORMANCE TEST: COMPETITIVE")
            print(f"   TPU shows competitive performance on {competitive_results}/{total_tests} graphs")
            print(f"   Performance optimization opportunities identified")
            return True
        else:
            print(f"\n‚ö†Ô∏è  EXTREME PERFORMANCE TEST: NEEDS OPTIMIZATION")
            print(f"   TPU performance needs algorithmic improvements")
            return False
    else:
        print("‚ùå No valid test results")
        return False


if __name__ == "__main__":
    # Minimal logging for cleaner output
    logging.basicConfig(level=logging.ERROR)
    
    success = run_extreme_performance_test()
    
    print(f"\n{'='*80}")
    if success:
        print("üèÜ CONCLUSION: TPU BFS shows performance benefits on large, high-parallelism graphs")
    else:
        print("üìä CONCLUSION: Further optimization needed for current graph sizes")
    print(f"{'='*80}")
    
    exit(0 if success else 1)